{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89667b22-565e-4eaf-af61-f98f8e486966",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c160b-8c21-448f-ab05-8c3b8a757189",
   "metadata": {
    "citation-manager": {
     "citations": {
      "9kn5i": [],
      "hj7ur": [],
      "jfsfh": []
     }
    }
   },
   "source": [
    "### In General:\n",
    "At the moment, LLMs, in general, struggle to understand sports, although LLMs can currently answer fact-based questions. When dealing with more rule-based, scenario, or expert-level questions that involve a true knowledge of sports, these LLMs really struggle <cite id=\"hj7ur\"><a href=\"#zotero%7C17220151%2FA7PNLSS5\">(Xia et al., 2024)</a></cite>.\n",
    "\n",
    "This is because discussing sports involves many terms and nuances that someone needs to understand in order to really talk about it and understand what they are talking about. Due to the nature of LLMs as \"next-word predictors,\" they seem confident and able to talk about sports <cite id=\"jfsfh\"><a href=\"#zotero%7C17220151%2FF8Z32QVX\">(<i>2. Introduction to Large Language Models for Text Generation</i>, n.d.)</a></cite>. But in reality, LLMs at the moment struggle to really understand sports. \n",
    "\n",
    "Often, even with fact-based questions, LLMs can hallucinate and provide false answers. This output can be dangerous for someone who doesn't know enough about the sport they are prompting about and thus, does not know that the output is false. This is due to a mix of factors. The main ones are that in general, AI hallucinates and the other being that most LLMs such as ChatGPT 3.5, are not up to date<cite id=\"9kn5i\"><a href=\"#zotero%7C17220151%2FIWZG4XZB\">(<i>1. The Five Principles of Prompting</i>, n.d.)</a></cite>. Thus, asking the model questions about a basketball game that happened last night will often yield false answers. \n",
    "\n",
    "It is very important that we understand what LLMs can and can not do at the moment.\n",
    "\n",
    "### Looking to the Future:\n",
    "However, the use of LLMs for Sports Analysts is bright. Research projects such as SportQA and SportsSett have really exciting implications for the future use of LLMs in sports analytics. In addition, my interactions with the Gemini 1.5 Pro model have shown me the power of current LLMs out there. \n",
    "\n",
    "I was very impressed by its skills in video analysis, player analysis, and creating reports. In the future, I hope to examine other tasks using the Gemini 1.5 Pro model, such as creating data visualizations, creating new metrics for player behavior, and analyzing play-by-plays. Through these future experiments, I hope to see if LLMs really understand sports or if they are just generating text based on articles they've been trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15367f-6420-4fee-8488-39ace66f681a",
   "metadata": {},
   "source": [
    "<!-- BIBLIOGRAPHY START -->\n",
    "<div class=\"csl-bib-body\">\n",
    "</div>\n",
    "<!-- BIBLIOGRAPHY END -->"
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3.11 (COMM4190)",
   "language": "python",
   "name": "comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
